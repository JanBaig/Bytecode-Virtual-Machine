
NOTES

- Learned about conditional preprocessing
- int* pointer, var1 [defining a pointer that holds addresses of variables of type Int]
  var1 = 10 
  pointer = &var1 [var1 is of type Int and therefore, pointer stores it's address]
- Going to have an array of instructions and each instruciton has an opcode (operation code)
- Chunk = [opcode, opcode, opcode, ...]
- Chunk is sequences of bytecode and contains an array of instructions
- We often pass by reference to alter the value directly in memory (not locally to the function)
- General execution structure: initVM() -> reset stack, initChunk() -> reset chunk attributes, [All operations], 
							   interpret() -> executes chunk instructions, freeVM(), freeChunk() -> deallocates all the chunks array attributes 
							   return 0
- Document the meaning of all the exit codes

QUESTIONS

- Why do we pass in pointers/references when we define/call functions?
	- When we pass a pointer as an argument instead of a variable then the address of the variable is passed instead of the value that is simply copied into the parameter space. 
	  So any change made by the function using the pointer is permanently made at the address of the passed variable. 
	  This technique is known as call by reference in C.
- Whats all the jazz about the offset calculation? Understand that.
- "Given a numeric opcode, we need to get to the right C code that implements that instruction’s semantics. 
  This process is called decoding or dispatching the instruction." -- Makes sense?

CHAPTER NOTES

- CHAPTER 14
	- Source Program -> (Compiler) -> ByteCode -> (Interpreted & Executed by) -> VM/Emulator
	- There is both compiling (First) and interpretation (Second) in play
	- JLOX was easy to implement and is portable. But it isn't the best choice because it is slow and memory inefficient.
	- JLOX does not exhibit spacial locality effectively. Leads to lots of overhead. Should arrange data to take advantage of 
	  CPU caching.
	- Processing data is fast (CPU), retriving data is slower (RAM)
	- Because of caching, the way you organize data directly impacts performance.
	- Bytecode adds a bit of overhead, but we get portability in return 
	- Interpretation happens in the VM
	- Chunk = Sequences of ByteCode
	- ByteCode = Series of Instructions (OPCode, Operands) [I1, I2, I3, ...]
	- ByteCode1, ByteCode2, ByteCode3 = Chunk Type

- CHAPTER 15 
	- IP = Instruction Pointer that points to the next instruction
	- vm.ip holds an address of the next intruction (pointing to it)
	  * gets the value at that address
	  increments the address 
	- READ_CONSTANT: Since the current IP holds the OPcode for the instruction, we make another call
					 to READ_BYTE and that returns the index of the constant and we later use that 
					 index and get the value of the constant  
					 For constants, the chunk->code stores the constant's index
					 Which is why read_byte would return an index which we can later use to get the 
					 value from the values array 
	- Offset is from the start of the chunk->code  
	- A static function in C has a scope that is limited to its object file.
	- The stack acts like a shared workspace allows all operations to read from and write to.


ROUGH
- OP_CONSTANT, Index, OP_CONSTANT, Index, OP_ADD, OP_CONSTANT, Index, OP_DIVIDE, OP_NEGATE, OP_RETURN
- vm->interpret->compile->scanner()
- [Object something] in jlox
- Later in the compiler, we’ll convert that lexeme to a runtime value right 
  when we are ready to store it in the chunk’s constant table.




